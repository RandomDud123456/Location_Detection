{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset, random_split\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "from transformers import ViTModel, ViTImageProcessor\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_folder, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image_path = os.path.join(self.image_folder, row['filename'])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            processed = self.transform(images=image, return_tensors=\"pt\")\n",
    "            image_tensor = processed[\"pixel_values\"].squeeze(0)\n",
    "        else:\n",
    "            image_tensor = transforms.ToTensor()(image)\n",
    "\n",
    "        latitude = float(row['latitude'])\n",
    "        longitude = float(row['longitude'])\n",
    "        coords = torch.tensor([latitude, longitude], dtype=torch.float32)\n",
    "        \n",
    "        region_id = int(row['Region_ID']) - 1  \n",
    "        region_id = torch.tensor(region_id, dtype=torch.long)\n",
    "        \n",
    "        return image_tensor, region_id, coords  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_resize(input_dir, output_dir, size=(224, 224), exts={'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}):\n",
    "    \"\"\"\n",
    "    Resize all images in input_dir to the given size and save them in output_dir.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Path to folder containing original images.\n",
    "        output_dir (str): Path to folder where resized images will be saved.\n",
    "        size (tuple): Desired output size, e.g. (224, 224).\n",
    "        exts (set): Image file extensions to process.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for fname in os.listdir(input_dir):\n",
    "        base, ext = os.path.splitext(fname)\n",
    "        if ext.lower() not in exts:\n",
    "            continue\n",
    "\n",
    "        in_path  = os.path.join(input_dir, fname)\n",
    "        out_path = os.path.join(output_dir, fname)\n",
    "\n",
    "        with Image.open(in_path) as img:\n",
    "            # Use high-quality downsampling filter\n",
    "            resized = img.resize(size, resample=Image.LANCZOS)  \n",
    "            resized.save(out_path)\n",
    "\n",
    "# Reszize images in the specified directories to 224x224 to fit the ViT model\n",
    "\n",
    "batch_resize(\n",
    "        input_dir=\"/data3/pratyush.jena/misc/MMT/SMAI_Project/Phase_2_data/Phase_2_data/images_train\",\n",
    "        output_dir=\"/data3/pratyush.jena/misc/MMT/SMAI_Project/Phase_2_data/Phase_2_data/images_train_new\",\n",
    "        size=(224, 224)\n",
    "    )\n",
    " \n",
    "batch_resize(\n",
    "        input_dir=\"/data3/pratyush.jena/misc/MMT/SMAI_Project/Phase_2_data/Phase_2_data/images_val\",\n",
    "        output_dir=\"/data3/pratyush.jena/misc/MMT/SMAI_Project/Phase_2_data/Phase_2_data/images_val_new\",\n",
    "        size=(224, 224)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    '/data3/pratyush.jena/misc/MMT/SMAI_Project/Phase_2_data/Phase_2_data/area_predictions_train.csv'\n",
    ")\n",
    "\n",
    "mask = (\n",
    "    (df['longitude'] < 140000) |\n",
    "    (df['longitude'] > 150000) |\n",
    "    (df['latitude']  < 200000) |\n",
    "    (df['latitude']  > 230000)\n",
    ")\n",
    "\n",
    "\n",
    "cleaned_df = df.loc[~mask]  \n",
    "\n",
    "cleaned_df.to_csv(\n",
    "    '/data3/pratyush.jena/misc/MMT/SMAI_Project/area_predictions_train_need.csv',\n",
    "    index=False\n",
    ") \n",
    "\n",
    "\n",
    "df = pd.read_csv(\n",
    "    '/data3/pratyush.jena/misc/MMT/SMAI_Project/Phase_2_data/Phase_2_data/area_predictions_val.csv'\n",
    ")\n",
    "\n",
    "mask = (\n",
    "    (df['longitude'] < 140000) |\n",
    "    (df['longitude'] > 150000) |\n",
    "    (df['latitude']  < 200000) |\n",
    "    (df['latitude']  > 230000)\n",
    ")\n",
    "\n",
    "\n",
    "cleaned_df = df.loc[~mask]  \n",
    "\n",
    "cleaned_df.to_csv(\n",
    "    '/data3/pratyush.jena/misc/MMT/SMAI_Project/area_predictions_val_cleaned.csv',\n",
    "    index=False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_path = '/data3/pratyush.jena/misc/MMT/SMAI_Project/area_predictions_train_need.csv'\n",
    "val_csv_path = '/data3/pratyush.jena/misc/MMT/SMAI_Project/area_predictions_val_cleaned.csv'\n",
    "train_images_folder = '/data3/pratyush.jena/misc/MMT/SMAI_Project/Phase_2_data/Phase_2_data/images_train_new'\n",
    "val_images_folder = '/data3/pratyush.jena/misc/MMT/SMAI_Project/Phase_2_data/Phase_2_data/images_val_new'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'google/vit-base-patch16-224-in21k'\n",
    "processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "vit = ViTModel.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "vit.to(device)\n",
    "\n",
    "random.seed(11)\n",
    "torch.manual_seed(11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GeoDataset(csv_file=train_csv_path, image_folder=train_images_folder, transform=processor)\n",
    "val_dataset = GeoDataset(csv_file=val_csv_path, image_folder=val_images_folder, transform=processor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"Train set size: {len(train_dataset)}\")\n",
    "print(f\"Val set size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(loader, model):\n",
    "    new_features = []\n",
    "    new_regions = []\n",
    "    new_coords = []\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, regions, coords in tqdm(loader, desc=\"Extracting features\", unit=\"batch\"):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(pixel_values=inputs)\n",
    "            cls_hidden_state = outputs.last_hidden_state[:, 0, :]\n",
    "            new_features.append(cls_hidden_state.cpu())\n",
    "            new_regions.append(regions)\n",
    "            new_coords.append(coords)\n",
    "    \n",
    "    return torch.cat(new_features), torch.cat(new_regions), torch.cat(new_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_regions, train_coords = extract_features(train_loader, vit)\n",
    "val_features, val_regions, val_coords = extract_features(val_loader, vit)\n",
    "\n",
    "train_inFeatures_dataset = TensorDataset(train_features, train_regions, train_coords)\n",
    "val_inFeatures_dataset = TensorDataset(val_features, val_regions, val_coords)\n",
    "\n",
    "train_loader_new = DataLoader(train_inFeatures_dataset, batch_size=16, shuffle=True)\n",
    "val_loader_new = DataLoader(val_inFeatures_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class geoNet(nn.Module):\n",
    "    def __init__(self, num_regions=15):\n",
    "        super(geoNet, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(768 + num_regions, 512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.regressor = nn.Linear(64, 2)\n",
    "\n",
    "        self.num_regions = num_regions\n",
    "\n",
    "    def forward(self, x, region_ids):\n",
    "        region_onehot = F.one_hot(region_ids, num_classes=self.num_regions).float()\n",
    "\n",
    "        combined = torch.cat([x, region_onehot], dim=1)\n",
    "\n",
    "        combined = F.relu(self.bn1(self.fc1(combined)))\n",
    "        combined = F.relu(self.bn2(self.fc2(combined)))\n",
    "        combined = F.relu(self.bn3(self.fc3(combined)))\n",
    "        combined = F.relu(self.bn4(self.fc4(combined)))\n",
    "        coords_pred = self.regressor(combined)\n",
    "        return coords_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mae(net, dataloader):\n",
    "    total_mae = 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, regions, coords in dataloader:\n",
    "            features, regions, coords = features.to(device), regions.to(device), coords.to(device)\n",
    "            preds = net(features, regions)\n",
    "            total_mae += F.l1_loss(preds, coords, reduction='sum').item()\n",
    "    return total_mae / len(dataloader.dataset)\n",
    "\n",
    "def calc_mse(net, dataloader, flag=False, csv_path='coords_preds.csv'):\n",
    "    coords_preds = []\n",
    "    batch_coords = []\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, regions, coords in dataloader:\n",
    "            features, regions, coords = features.to(device), regions.to(device), coords.to(device)\n",
    "            preds = net(features, regions)\n",
    "            coords_preds.extend(preds.cpu().numpy())\n",
    "            batch_coords.extend(coords.cpu().numpy())\n",
    "    \n",
    "    coords_preds = np.array(coords_preds)\n",
    "    batch_coords = np.array(batch_coords)\n",
    "    \n",
    "    if flag:\n",
    "        df_out = pd.DataFrame({\n",
    "            'id': np.arange(coords_preds.shape[0]),\n",
    "            'Latitude': coords_preds[:, 0],\n",
    "            'Longitude': coords_preds[:, 1]\n",
    "        })\n",
    "        df_out.to_csv(csv_path, index=False)\n",
    "        print(f\"Predictions saved to {csv_path}\")\n",
    "    \n",
    "    return np.mean((coords_preds - batch_coords) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(model, train_loader, val_loader, num_epochs, learning_rate, patience=10):\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.1)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_maes = []\n",
    "    best_mae = float('inf')\n",
    "    best_model_wts = None\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for features, regions, coords in train_loader:\n",
    "            features, regions, coords = features.to(device), regions.to(device), coords.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features, regions)\n",
    "            loss = criterion(outputs, coords)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * features.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        val_mae = calc_mae(model, val_loader)\n",
    "        val_maes.append(val_mae)\n",
    "        \n",
    "        scheduler.step(val_mae)\n",
    "        \n",
    "        if val_mae < best_mae:\n",
    "            best_mae = val_mae\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "        print(f'Train Loss: {epoch_loss:.4f} | Val MAE: {val_mae:.4f}')\n",
    "        \n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f'\\nEarly stopping after {patience} epochs without improvement')\n",
    "            break\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    torch.save(model.state_dict(), 'best_model_coord.pt')\n",
    "    \n",
    "    val_mae = calc_mae(model, val_loader)\n",
    "    val_mse = calc_mse(model, val_loader, flag=True)\n",
    "    print(f'\\nFinal Evaluation:')\n",
    "    print(f'Val MAE: {val_mae:.4f} | Val MSE: {val_mse:.4f}')\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.title('Training Loss Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_maes, label='Validation MAE')\n",
    "    plt.title('Validation MAE Curve')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = geoNet()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    print('CUDA is available! Training on GPU ...')\n",
    "else:\n",
    "    print('CUDA is not available. Training on CPU ...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_net(model, \n",
    "         train_loader_new, \n",
    "         val_loader_new, \n",
    "         num_epochs=100,\n",
    "         learning_rate=1e-3,\n",
    "         patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = geoNet()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    print('CUDA is available! Training on GPU ...')\n",
    "else:\n",
    "    print('CUDA is not available. Training on CPU ...')\n",
    "    \n",
    "model.load_state_dict(torch.load('best_model_coord.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "calc_mse(model, val_loader_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv     = \"/data3/pratyush.jena/misc/MMT/SMAI_Project/area_predictions_test_with_filenames.csv\" #(Created using test images and image numbers)\n",
    "test_img_dir = \"/data3/pratyush.jena/misc/MMT/SMAI_Project/Phase_2_data/Phase_2_data/images_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = geoNet().to(device)\n",
    "checkpoint = torch.load('best_model_coord.pt', map_location=device)\n",
    "net.load_state_dict(checkpoint)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(test_csv)  \n",
    "df_test['Region_ID0'] = df_test['Region_ID'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGeoDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, processor):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.proc = processor\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        img = Image.open(os.path.join(self.img_dir, row.filename)).convert('RGB')\n",
    "        px = self.proc(images=img, return_tensors='pt')['pixel_values'].squeeze(0)\n",
    "        return px, torch.tensor(row.Region_ID0, dtype=torch.long), row.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = TestGeoDataset(df_test, test_img_dir, processor)\n",
    "test_loader = DataLoader(test_ds, batch_size=16, shuffle=False)\n",
    "vit = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k').to(device)\n",
    "vit.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction\n",
    "features, region_ids, ids = [], [], []\n",
    "with torch.no_grad():\n",
    "    for px, rid, idx in test_loader:\n",
    "        px = px.to(device)\n",
    "        out = vit(pixel_values=px).last_hidden_state[:,0,:]\n",
    "        features.append(out.cpu())\n",
    "        region_ids.append(rid)\n",
    "        ids.extend(idx.numpy().tolist())\n",
    "features = torch.cat(features)\n",
    "region_ids = torch.cat(region_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    coords_pred = net(features.to(device), region_ids.to(device)).cpu().numpy()\n",
    "\n",
    "# Save yesman.csv\n",
    "df_out = pd.DataFrame({\n",
    "    'id':       ids,\n",
    "    'Latitude':  coords_pred[:,0],\n",
    "    'Longitude': coords_pred[:,1]\n",
    "})\n",
    "df_out.to_csv('co_test.csv', index=False)\n",
    "print(f\"Saved {len(df_out)} rows to co_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('co_test.csv')\n",
    "\n",
    "# Add 369 to every value in the 'id' column\n",
    "df['id'] = df['id'] - 369\n",
    "\n",
    "# Save the updated DataFrame back to CSV\n",
    "df.to_csv('co_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMT_Proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
